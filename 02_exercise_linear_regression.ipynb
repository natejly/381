{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0fsGaVMMpwG"
      },
      "source": [
        "**Exercise 2: Linear Regression**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "\n",
        "4. Move the 02_exercise_linear_regression.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/01_exercise_linear_regression.ipynb\n",
        "```\n",
        "\n",
        "In this exercise, we will optimize a linear function for the regression task using the normal equation and pseudo-inverse methods. We will test them on several datasets.\n",
        "\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your training, validation, and testing scores.\n",
        "\n",
        "```\n",
        "Report training, validation, and testing scores here.\n",
        "\n",
        "Note: for full points, you must be able to reproduce the same scores as linear regression from scikit learn.\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: Doe, Jane (Please write names in <Last Name, First Name> format)\n",
        "\n",
        "Collaboration details: Discussed ... implementation details with Jane Doe.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxeZsiCGC0J8"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uumvcyiQ-k21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "import sklearn.metrics as skmetrics\n",
        "from sklearn.linear_model import LinearRegression as LinearRegressionSciKit\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "np.random.seed = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ljMielQC7Lg"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6wlWiioqDBkG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Implementation of linear regression by directly solving normal equation or pseudo-inverse\n",
        "'''\n",
        "class LinearRegression(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define private variables\n",
        "        self.__weights = None\n",
        "\n",
        "    def __fit_normal_equation(self, X, y):\n",
        "        '''\n",
        "        Fits the model to x and y via normal equation\n",
        "\n",
        "        Arg(s):\n",
        "            X : numpy\n",
        "                N x d feature vector\n",
        "            y : numpy\n",
        "                N x 1 ground-truth label\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the __fit_normal_equation function\n",
        "\n",
        "        # Normal equation: w* = (X.TX)^-1 X.Ty\n",
        "\n",
        "        # X.TX\n",
        "        X_t_X = np.matmul(X.T, X)\n",
        "\n",
        "        # Inverse of X.TX\n",
        "        X_t_X_inverse = np.linalg.inv(X_t_X)\n",
        "\n",
        "        # (X.TX)^-1 X.Ty\n",
        "        self.__weights = np.matmul(np.matmul(X_t_X_inverse, X.T), y)\n",
        "\n",
        "    def __fit_pseudoinverse(self, X, y):\n",
        "        '''\n",
        "        Fits the model to x and y via pseudo-inverse\n",
        "\n",
        "        Arg(s):\n",
        "            X : numpy\n",
        "                N x d feature vector\n",
        "            y : numpy\n",
        "                N x 1 ground-truth label\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the __fit_pseudoinverse function\n",
        "\n",
        "        self.__weights = None\n",
        "\n",
        "        # To get pseudoinverse of X\n",
        "        # 1. compute U, S, V_t from SVD\n",
        "        # 2. S+ take reciprocal of S and transpose the result\n",
        "        # 3. multiply V S+ U.T to get X+\n",
        "\n",
        "        # Assume X is (N, d)\n",
        "        # Compute SVD gives us U (N, N), S (N, d), V_t (d, d)\n",
        "        U, S, V_t = np.linalg.svd(X)\n",
        "\n",
        "        # This actually gives us U (N, N), S (d), V_t (d, d)\n",
        "        # So we need to convert S (d) to (N, d)\n",
        "        S_plus = np.diag(1.0 / S)  # We will have a (d, d)\n",
        "\n",
        "        padding = np.zeros([U.shape[0] - S_plus.shape[0], S_plus.shape[0]])\n",
        "\n",
        "        # We need to turn this into a (N, d) matrix\n",
        "        # We know S should be zeros everywhere else, so we will just pad it with zeros\n",
        "        # Specifically, we need to pad N-d along the 0-th dimension\n",
        "        # and d along the 1-st dimension\n",
        "        # U.shape[0] gives us N, S_plus.shape[0] gives us d\n",
        "\n",
        "        # S+\n",
        "        S_plus = np.concatenate([S_plus, padding], axis=0)\n",
        "\n",
        "        # To get S+, we need to transpose it\n",
        "        S_plus  = S_plus .T\n",
        "\n",
        "        # X+ = V S+ U.T\n",
        "        # Since we are given V_t we need to tranpose V_t\n",
        "        X_plus = np.matmul(np.matmul(V_t.T, S_plus), U.T)\n",
        "\n",
        "        # Solution: w+ = X+ y\n",
        "        self.__weights = np.matmul(X_plus, y)\n",
        "\n",
        "    def fit(self, x, y, solver='normal_equation'):\n",
        "        '''\n",
        "        Fits the model to x and y by solving the ordinary least squares\n",
        "        using normal equation or pseudoinverse (SVD)\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy[float32]\n",
        "                d x N feature vector\n",
        "            y : numpy[float32]\n",
        "                1 x N ground-truth label\n",
        "            solver : str\n",
        "                solver types: normal_equation, pseudoinverse\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the fit function\n",
        "\n",
        "        X = x.T\n",
        "        Y = y.T\n",
        "\n",
        "        if solver == 'normal_equation':\n",
        "            self.__fit_normal_equation(X, Y)\n",
        "        elif solver == 'pseudoinverse':\n",
        "            self.__fit_pseudoinverse(X, Y)\n",
        "        else:\n",
        "            raise ValueError('Encountered unsupported solver: {}'.format(solver))\n",
        "\n",
        "    def predict(self, x):\n",
        "        '''\n",
        "        Predicts the real value for each feature vector x\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy[float32]\n",
        "                d x N feature vector\n",
        "        Returns:\n",
        "            numpy[float32] : 1 x N real value vector (\\hat{y})\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the predict function\n",
        "\n",
        "        return np.matmul(self.__weights.T, x)\n",
        "\n",
        "    def __score_r_squared(self, y_hat, y):\n",
        "        '''\n",
        "        Measures the r-squared score from groundtruth y\n",
        "\n",
        "        Args:\n",
        "            y_hat : numpy[float32]\n",
        "                1 x N predictions\n",
        "            y : numpy[float32]\n",
        "                1 x N ground-truth label\n",
        "\n",
        "        Returns:\n",
        "            float : r-squared score\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the __score_r_squared function\n",
        "\n",
        "        # R2 = 1 - u / v\n",
        "        # Unexplained variation (u): sum (y_hat - y)^2\n",
        "        sum_squared_errors = np.sum((y_hat - y) ** 2)\n",
        "\n",
        "        # Total variation in data: sum (y_hat - y_mean)^2\n",
        "        sum_unexplained_var = np.sum((y - np.mean(y)) ** 2)\n",
        "\n",
        "        return 1 - (sum_squared_errors / sum_unexplained_var)\n",
        "\n",
        "    def __score_mean_squared_error(self, y_hat, y):\n",
        "        '''\n",
        "        Measures the mean squared error (distance) from groundtruth y\n",
        "\n",
        "        Arg(s):\n",
        "            y_hat : numpy[float32]\n",
        "                1 x N predictions\n",
        "            y : numpy[float32]\n",
        "                1 x N ground-truth label\n",
        "\n",
        "        Returns:\n",
        "            float : mean squared error (mse)\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the __score_mean_squared_error function\n",
        "\n",
        "        return np.mean((y_hat - y) ** 2)\n",
        "\n",
        "    def score(self, x, y, scoring_func='r_squared'):\n",
        "        '''\n",
        "        Predicts real values from x and measures the mean squared error (distance)\n",
        "        or r-squared from groundtruth y\n",
        "\n",
        "        Arg(s):\n",
        "            x : numpy[float32]\n",
        "                d x N feature vector\n",
        "            y : numpy[float32]\n",
        "                1 x N ground-truth label\n",
        "            scoring_func : str\n",
        "                scoring function: r_squared, mean_squared_error\n",
        "\n",
        "        Returns:\n",
        "            float : mean squared error (mse)\n",
        "        '''\n",
        "\n",
        "        # TODO: Implement the score function\n",
        "\n",
        "        y_hat = self.predict(x)\n",
        "\n",
        "        if scoring_func == 'r_squared':\n",
        "            return self.__score_r_squared(y_hat, y)\n",
        "        elif scoring_func == 'mean_squared_error':\n",
        "            return self.__score_mean_squared_error(y_hat, y)\n",
        "        else:\n",
        "            # Complain\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcb2TArNKvf1"
      },
      "source": [
        "Implementing training and validation loop for linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB29ajtrK8sQ",
        "outputId": "10fbb37c-b13a-4fac-ec3d-dd97e72f1906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** Results of scikit-learn linear regression model on diabetes dataset *****\n",
            "Training set mean squared error: 25533.3113\n",
            "Training set r-squared scores: -3.3575\n",
            "Validation set mean squared error: 28544.1907\n",
            "Validation set r-squared scores: -3.3752\n",
            "Testing set mean squared error: 29466.3058\n",
            "Testing set r-squared scores: -4.1215\n",
            "***** Results of our linear regression model trained with normal_equation on diabetes dataset *****\n",
            "Training set mean squared error: 25533.3113\n",
            "Training set r-squared scores: -3.3575\n",
            "Validation set mean squared error: 28544.1907\n",
            "Validation set r-squared scores: -3.3752\n",
            "Testing set mean squared error: 29466.3058\n",
            "Testing set r-squared scores: -4.1215\n",
            "***** Results of our linear regression model trained with pseudoinverse on diabetes dataset *****\n",
            "Training set mean squared error: 25533.3113\n",
            "Training set r-squared scores: -3.3575\n",
            "Validation set mean squared error: 28544.1907\n",
            "Validation set r-squared scores: -3.3752\n",
            "Testing set mean squared error: 29466.3058\n",
            "Testing set r-squared scores: -4.1215\n",
            "***** Results of scikit-learn linear regression model on California housing prices dataset *****\n",
            "Training set mean squared error: 0.6084\n",
            "Training set r-squared scores: 0.5452\n",
            "Validation set mean squared error: 0.5620\n",
            "Validation set r-squared scores: 0.5562\n",
            "Testing set mean squared error: 0.6145\n",
            "Testing set r-squared scores: 0.5440\n",
            "***** Results of our linear regression model trained with normal_equation on California housing prices dataset *****\n",
            "Training set mean squared error: 0.6084\n",
            "Training set r-squared scores: 0.5452\n",
            "Validation set mean squared error: 0.5620\n",
            "Validation set r-squared scores: 0.5562\n",
            "Testing set mean squared error: 0.6145\n",
            "Testing set r-squared scores: 0.5440\n",
            "***** Results of our linear regression model trained with pseudoinverse on California housing prices dataset *****\n",
            "Training set mean squared error: 0.6084\n",
            "Training set r-squared scores: 0.5452\n",
            "Validation set mean squared error: 0.5620\n",
            "Validation set r-squared scores: 0.5562\n",
            "Testing set mean squared error: 0.6145\n",
            "Testing set r-squared scores: 0.5440\n"
          ]
        }
      ],
      "source": [
        "# Load diabetes and California housing prices dataset\n",
        "datasets = [skdata.load_diabetes(), skdata.fetch_california_housing()]\n",
        "dataset_names = ['diabetes', 'California housing prices']\n",
        "\n",
        "for dataset, dataset_name in zip(datasets, dataset_names):\n",
        "    '''\n",
        "    Create the training, validation and testing splits\n",
        "    '''\n",
        "    x = dataset.data\n",
        "    y = dataset.target\n",
        "\n",
        "    # Shuffle the dataset based on sample indices\n",
        "    shuffled_indices = np.random.permutation(x.shape[0])\n",
        "\n",
        "    # Choose the first 80% as training set, next 10% as validation and the rest as testing\n",
        "    train_split_idx = int(0.80 * x.shape[0])\n",
        "    val_split_idx = int(0.90 * x.shape[0])\n",
        "\n",
        "    train_indices = shuffled_indices[0:train_split_idx]\n",
        "    val_indices = shuffled_indices[train_split_idx:val_split_idx]\n",
        "    test_indices = shuffled_indices[val_split_idx:]\n",
        "\n",
        "    # Select the examples from x and y to construct our training, validation, testing sets\n",
        "    x_train, y_train = x[train_indices, :], y[train_indices]\n",
        "    x_val, y_val = x[val_indices, :], y[val_indices]\n",
        "    x_test, y_test = x[test_indices, :], y[test_indices]\n",
        "\n",
        "    '''\n",
        "    Trains and tests Perceptron model from scikit-learn\n",
        "    '''\n",
        "    # TODO: Initialize scikit-learn linear regression model without bias\n",
        "    model_scikit = LinearRegressionSciKit(fit_intercept=False)\n",
        "\n",
        "    # TODO: Trains scikit-learn linear regression model\n",
        "    model_scikit.fit(x_train, y_train)\n",
        "\n",
        "    print('***** Results of scikit-learn linear regression model on {} dataset *****'.format(\n",
        "        dataset_name))\n",
        "\n",
        "    # TODO: Test model on training set\n",
        "    predictions_train = model_scikit.predict(x_train)\n",
        "\n",
        "    score_mse_train = skmetrics.mean_squared_error(y_train, predictions_train)\n",
        "    print('Training set mean squared error: {:.4f}'.format(score_mse_train))\n",
        "\n",
        "    score_r2_train = skmetrics.r2_score(y_train, predictions_train)\n",
        "    print('Training set r-squared scores: {:.4f}'.format(score_r2_train))\n",
        "\n",
        "    # TODO: Test model on validation set\n",
        "    predictions_val =  model_scikit.predict(x_val)\n",
        "\n",
        "    score_mse_val = skmetrics.mean_squared_error(y_val, predictions_val)\n",
        "    print('Validation set mean squared error: {:.4f}'.format(score_mse_val))\n",
        "\n",
        "    score_r2_val = skmetrics.r2_score(y_val, predictions_val)\n",
        "    print('Validation set r-squared scores: {:.4f}'.format(score_r2_val))\n",
        "\n",
        "    # TODO: Test model on testing set\n",
        "    predictions_test = model_scikit.predict(x_test)\n",
        "\n",
        "    score_mse_test = skmetrics.mean_squared_error(y_test, predictions_test)\n",
        "    print('Testing set mean squared error: {:.4f}'.format(score_mse_test))\n",
        "\n",
        "    score_r2_test = skmetrics.r2_score(y_test, predictions_test)\n",
        "    print('Testing set r-squared scores: {:.4f}'.format(score_r2_test))\n",
        "\n",
        "    '''\n",
        "    Trains and tests our linear regression model using different solvers\n",
        "    '''\n",
        "\n",
        "    # TODO: Take the transpose of the dataset to match the dimensions discussed in lecture\n",
        "    # i.e., (N x d) to (d x N)\n",
        "    x_train = x_train.T\n",
        "    x_val = x_val.T\n",
        "    x_test = x_test.T\n",
        "\n",
        "    # Train 2 linear regression models using normal equation and pseudoinverse\n",
        "    solvers = ['normal_equation', 'pseudoinverse']\n",
        "\n",
        "    for solver in solvers:\n",
        "        # TODO: Initialize our linear regression model\n",
        "        model_ours = LinearRegression()\n",
        "\n",
        "        print('***** Results of our linear regression model trained with {} on {} dataset *****'.format(\n",
        "            solver, dataset_name))\n",
        "\n",
        "        # TODO: Train model on training set\n",
        "        model_ours.fit(x_train, y_train, solver=solver)\n",
        "\n",
        "        # TODO: Test model on training set using mean squared error and r-squared\n",
        "        score_mse_train = model_ours.score(x_train, y_train, scoring_func='mean_squared_error')\n",
        "        print('Training set mean squared error: {:.4f}'.format(score_mse_train))\n",
        "\n",
        "        score_r2_train = model_ours.score(x_train, y_train, scoring_func='r_squared')\n",
        "        print('Training set r-squared scores: {:.4f}'.format(score_r2_train))\n",
        "\n",
        "        # TODO: Test model on validation set using mean squared error and r-squared\n",
        "        score_mse_val = model_ours.score(x_val, y_val, scoring_func='mean_squared_error')\n",
        "        print('Validation set mean squared error: {:.4f}'.format(score_mse_val))\n",
        "\n",
        "        score_r2_val = model_ours.score(x_val, y_val, scoring_func='r_squared')\n",
        "        print('Validation set r-squared scores: {:.4f}'.format(score_r2_val))\n",
        "\n",
        "        # TODO: Test model on testing set using mean squared error and r-squared\n",
        "        score_mse_test = model_ours.score(x_test, y_test, scoring_func='mean_squared_error')\n",
        "        print('Testing set mean squared error: {:.4f}'.format(score_mse_test))\n",
        "\n",
        "        score_r2_test = model_ours.score(x_test, y_test, scoring_func='r_squared')\n",
        "        print('Testing set r-squared scores: {:.4f}'.format(score_r2_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
