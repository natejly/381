{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0fsGaVMMpwG"
      },
      "source": [
        "**Exercise 1: Training, Validation, and Testing a Perceptron**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "\n",
        "4. Move the 01_exercise.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/01_exercise.ipynb\n",
        "```\n",
        "\n",
        "In this exercise, we will introduce basic data handling using NumPy to create training, validation and testing splits. We will implement a training and validation loop for a Perceptron and test it on the testing split.\n",
        "\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your validation and testing scores.\n",
        "\n",
        "```\n",
        "Report validation and testing scores here. For example,\n",
        "\n",
        "Max training iterations: 1\n",
        "Training loss: 0.18681  Validation accuracy: 80.70%\n",
        "Max training iterations: 2\n",
        "Training loss: 0.61978  Validation accuracy: 43.86%\n",
        "Max training iterations: 3\n",
        "Training loss: 0.08791  Validation accuracy: 87.72%\n",
        "Max training iterations: 4\n",
        "Training loss: 0.08352  Validation accuracy: 91.23%\n",
        "\n",
        "Test accuracy: 87.72%\n",
        "\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: Doe, Jane (Please write names in <Last Name, First Name> format)\n",
        "\n",
        "Collaboration details: Discussed ... implementation details with Jane Doe.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxeZsiCGC0J8"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzIMN8VNjUxV"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn==1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uumvcyiQ-k21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "from sklearn.linear_model import Perceptron\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ljMielQC7Lg"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wlWiioqDBkG"
      },
      "outputs": [],
      "source": [
        "# TODO: Load breast cancer dataset\n",
        "# dictionary object keyed by data, target, target_names, feature_names, ...\n",
        "breast_cancer_data = None\n",
        "\n",
        "# TODO: Get data, target, target_names, and feature_names from the dataset\n",
        "x = None\n",
        "y = None\n",
        "target_names = None\n",
        "feature_names = None\n",
        "\n",
        "# TODO: Print the number of samples and features in the dataset\n",
        "\n",
        "# TODO: Check to make sure that there are the same number of ground truth\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgFKGRDagRNz"
      },
      "source": [
        "Accessing the features of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d85Zv7nifE3e"
      },
      "outputs": [],
      "source": [
        "# TODO: Examine the dataset by showing the first two data points\n",
        "# Print each feature name and value in each line \"<name>: <value>\" followed by \"target: <name> (<value>)\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v01ndhtiEoWh"
      },
      "source": [
        "Creating the training, validation and testing splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYV_5EGeEvKy"
      },
      "outputs": [],
      "source": [
        "# TODO: Shuffle the dataset based on sample indices\n",
        "shuffled_indices = None\n",
        "\n",
        "# TODO: Choose the first 80% as training set, next 10% as validation and the rest as testing\n",
        "train_split_idx = None\n",
        "val_split_idx = None\n",
        "\n",
        "train_indices = None\n",
        "val_indices = None\n",
        "test_indices = None\n",
        "\n",
        "# TODO: Select the examples from x and y to construct our training, validation, testing sets\n",
        "x_train, y_train = None, None\n",
        "x_val, y_val = None, None\n",
        "x_test, y_test = None, None\n",
        "\n",
        "# TODO: Print the number of samples in training, validation and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcb2TArNKvf1"
      },
      "source": [
        "Implementing training and validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FYhX9G7unRw"
      },
      "outputs": [],
      "source": [
        "def mean_accuracy(predictions, ground_truths):\n",
        "    '''\n",
        "    Computes the mean accuracy between predictions and ground truths\n",
        "\n",
        "    Arg(s):\n",
        "        predictions : numpy[int64]\n",
        "            predictions (y_hat)\n",
        "        ground_truths : numpy[int64]\n",
        "            groundtruth labels (y)\n",
        "    Returns:\n",
        "        float : mean accuracy score\n",
        "    '''\n",
        "\n",
        "    # TODO: Implement mean accuracy\n",
        "    mean_accuracy = 0.0\n",
        "\n",
        "    return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB29ajtrK8sQ"
      },
      "outputs": [],
      "source": [
        "# Define a list to store perceptron models\n",
        "models = []\n",
        "\n",
        "# Define a list of max iterations\n",
        "max_iterations = [1, 2, 3, 4]\n",
        "\n",
        "# Define a list to store training losses and validation accuracy scores\n",
        "losses_train = []\n",
        "mean_accuracies_val = []\n",
        "\n",
        "for max_iter in max_iterations:\n",
        "\n",
        "    '''\n",
        "    Training the perceptron model\n",
        "    '''\n",
        "    # TODO: Set up our Perceptron model\n",
        "    # max_iter is the maximum iterations through the data for training the perceptron\n",
        "    # penalty and alpha relates to regularization (which we havenâ€™t covered so ignore them)\n",
        "    model = None\n",
        "\n",
        "    # TODO: Train our perceptron model on the training set using fit function\n",
        "\n",
        "\n",
        "    # TODO: Store model into list of models\n",
        "\n",
        "\n",
        "    # TODO: Make predictions on the training set using the predict function\n",
        "    y_hat_train = None\n",
        "\n",
        "    # TODO: Compute the loss on the training set\n",
        "    scores_train = None\n",
        "    loss_train = None\n",
        "\n",
        "    # TODO: Store the loss into our list of losses\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    Validate our perceptron model on the validation set\n",
        "    '''\n",
        "    # TODO: Make predictions on the validation set using the predict function\n",
        "    y_hat_val = None\n",
        "\n",
        "    # TODO: Compute the accuracy on the validation set\n",
        "    # Note that we will be using this again in the test set, please refactor this into the mean_accuracy function above\n",
        "    # and call that instead for both\n",
        "    accuracy_val = None\n",
        "    mean_accuracy_val = None\n",
        "\n",
        "    # TODO: Store the score into the list of validation mean accuracies\n",
        "\n",
        "\n",
        "    print('Max training iterations: {}'.format(max_iter))\n",
        "    print('Training loss: {:0.5f}  Validation accuracy: {:0.2f}%'.format(loss_train, 100 * mean_accuracy_val))\n",
        "\n",
        "# TODO: Choose the best model based on highest validation accuracy\n",
        "best_model_idx = None\n",
        "best_model = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSApmaTZtlp6"
      },
      "source": [
        "Testing our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsdZWwJMtlFS"
      },
      "outputs": [],
      "source": [
        "# TODO: Make predictions on the testing set using our best model\n",
        "y_hat_test = None\n",
        "\n",
        "# TODO: Compute the accuracy on the testing set\n",
        "accuracy_test = None\n",
        "mean_accuracy_test = 0.0\n",
        "\n",
        "print('Test accuracy: {:0.2f}%'.format(100 * mean_accuracy_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
